{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to first load in the words in our NRC Emotion Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = dict()\n",
    "\n",
    "with open('./data/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        emotion_lexicon = line.strip('\\n')\n",
    "        emotion_lexicon_entry = emotion_lexicon.split('\\t')\n",
    "        if emotion_lexicon_entry[0] not in emotions:\n",
    "            emotions[emotion_lexicon_entry[0]] = dict()\n",
    "        emotions[emotion_lexicon_entry[0]][emotion_lexicon_entry[1]] = int(emotion_lexicon_entry[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the subreddit data files for specialized and generalized subreddits and combine them into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in specialized dataset\n",
    "guitars_df = pd.read_csv('./data/specialized/negative_comments_guitars_w_replies.csv')\n",
    "piano_df = pd.read_csv('./data/specialized/negative_comments_piano_w_replies.csv')\n",
    "photography_df = pd.read_csv('./data/specialized/negative_comments_photography_w_replies.csv')\n",
    "\n",
    "# combine into one dataframe\n",
    "specialized_df = pd.concat([guitars_df, piano_df, photography_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in generalized dataset\n",
    "askReddit_df = pd.read_csv('./data/generalized/negative_comments_AskReddit_w_replies.csv')\n",
    "funny_df = pd.read_csv('./data/generalized/negative_comments_funny_w_replies.csv')\n",
    "todayilearned_df = pd.read_csv('./data/generalized/negative_comments_todayilearned_w_replies.csv')\n",
    "\n",
    "# combine into one dataframe\n",
    "generalized_df = pd.concat([askReddit_df, funny_df, todayilearned_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First pre-processing that we need to do is to get rid of entries where there are no replies. This is because they will not help us answer our questions regarding the sentiment of replies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialized_df_wo_empty_replies = specialized_df[specialized_df['reply'].notna()]\n",
    "generalized_df_wo_empty_replies = generalized_df[generalized_df['reply'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do replies to negatively voted comments differ in attitude between specialized and generalized communities?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will move on to getting the emotion scores for each comment and their reply. We will do so by using the NRC Emotion Lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_scores(comment):\n",
    "    # first tokenize the comment body\n",
    "    tokens = word_tokenize(comment)\n",
    "\n",
    "    # get emotion scores for each token\n",
    "    comment_emotions = []\n",
    "    for token in tokens:\n",
    "        if token in emotions:\n",
    "            comment_emotions.append(emotions[token])\n",
    "    \n",
    "    # now we want to add up the emotion scores for each comment and reply\n",
    "    comment_emotion_score = dict()\n",
    "    for scores in comment_emotions:\n",
    "        for emotion, score in scores.items():\n",
    "            if emotion not in comment_emotion_score:\n",
    "                comment_emotion_score[emotion] = 0\n",
    "            comment_emotion_score[emotion] += score\n",
    "\n",
    "    return comment_emotion_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to run the above function for every comment reply pair, and then store the results in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotions_df(df):\n",
    "    comments = df['body'].tolist()\n",
    "    replies = df['reply'].tolist()\n",
    "\n",
    "    # get emotions for comments and replies in df\n",
    "    comment_emotion = []\n",
    "    reply_emotion = []\n",
    "    for i in range(len(comments)):\n",
    "        comment_emotion.append(get_emotion_scores(comments[i]))\n",
    "        reply_emotion.append(get_emotion_scores(replies[i]))\n",
    "\n",
    "    # create dfs from emotions lists\n",
    "    comment_emotions_df = pd.DataFrame(comment_emotion)\n",
    "    reply_emotions_df = pd.DataFrame(reply_emotion)\n",
    "    emotions_df = comment_emotions_df.merge(reply_emotions_df, left_index=True, right_index=True, suffixes=('_comment', '_reply'))\n",
    "\n",
    "    return emotions_df.dropna(), comment_emotions_df.dropna(), reply_emotions_df.dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the combined emotion dataframe, comment emotion dataframe, and reply emotion dataframe for specialized and generalized datasets\n",
    "sp_emotions_df, sp_comment_emotions_df, sp_reply_emotions_df = get_emotions_df(specialized_df_wo_empty_replies)\n",
    "g_emotions_df, g_comment_emotions_df, g_reply_emotions_df = get_emotions_df(generalized_df_wo_empty_replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sums of each emotion for the replies in the specialized and generalized datasets\n",
    "sp_reply_emotion_sums = sp_reply_emotions_df.drop(['positive', 'negative'], axis=1).sum().sort_values(ascending=False)\n",
    "g_reply_emotion_sums = g_reply_emotions_df.drop(['positive', 'negative'], axis=1).sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sums of each polarity for the replies in the specialized and generalized datasets\n",
    "sp_reply_polarity = sp_reply_emotions_df[['positive', 'negative']].sum().sort_values(ascending=False)\n",
    "g_reply_polarity = g_reply_emotions_df[['positive', 'negative']].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we want consistent colors for emotions for all our graphs, we will assign a color to each emotion\n",
    "emotion_color_map = {'trust': 'cornflowerblue', 'anticipation': 'orange', 'joy': 'palegreen', 'fear': 'orangered', 'anger': 'violet', 'disgust': 'grey', 'sadness': 'peachpuff', 'surprise': 'pink'}\n",
    "\n",
    "# get the colors for each emotion for the specialized and generalized datasets\n",
    "sp_emotion_colors = [emotion_color_map[label] for label in sp_reply_emotion_sums.index]\n",
    "g_emotion_colors = [emotion_color_map[label] for label in g_reply_emotion_sums.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pie(sp_reply_emotion_sums.values, labels=sp_reply_emotion_sums.index, autopct='%1.1f%%', colors=sp_emotion_colors)\n",
    "plt.title(\"Specialized Subreddits Reply Emotion Sums\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.pie(sp_reply_polarity.values, labels=sp_reply_polarity.index, autopct='%1.1f%%')\n",
    "plt.title(\"Specialized Subreddits Reply Polarity Sums\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the ordering of the emotions is as follows: trust, anticipation, joy, fear, anger, sadness, surprise, and disgust.\n",
    "We also notice that the sum of positive emotions is roughly double that of the sum of negative emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pie(g_reply_emotion_sums.values, labels=g_reply_emotion_sums.index, autopct='%1.1f%%', colors=g_emotion_colors)\n",
    "plt.title(\"Generalized Subreddits Reply Emotion Sums\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.pie(g_reply_polarity.values, labels=g_reply_polarity.index, autopct='%1.1f%%')\n",
    "plt.title(\"Generalized Subreddits Reply Polarity Sums\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the ordering of emotions is as follows: trust, fear, anger, sadness, anticipation, joy, disgust and surprise.\n",
    "We also see that positive emotions and negative emotions have roughly the same sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graphs, we can make some conclusions.\n",
    "\n",
    "Looking at the Emotion Sums graphs for the specialized and generalized communities, we can see that specialized communities have a higher percentage of \"positive\" emotions such as \"anticipation\" and \"joy\", whereas generalized communities have a higher percentage of \"negative\" emotions such as \"anger\", \"fear\" and \"sadness\". \n",
    "\n",
    "We can also look at the Polarity Sums graph for the two types of communities, and we can see that specialized communities have a higher percentage of \"positive\" polarity for their comment replies than generalized communities (where the split is more even).\n",
    "\n",
    "From this, we can conlude that specialized communities have a higher percentage of \"positive\" emotions and polarity in their comment replies than generalized communities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. How do the attitudes of the replies relate to the attitudes of the initial comment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to explore the relationship between a comment's emotion score and its reply's emotion score. Primarily, we want to explore how a comment's emotion score will influence the reply's emotion score within these two communities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this by calculating the frequency with which each emotion in a comment appears with an emotion in a reply. We will first do this for the generalized communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these labels will help us in calculating the emotion and polarity frequencies.\n",
    "emotion_labels = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust']\n",
    "polarity_labels = ['positive', 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will add in the keys to the total_emotion_freq and total_polarity_freq dictionaries\n",
    "def init_freq_dicts():\n",
    "    total_emotion_freq = dict()\n",
    "    total_polarity_freq = dict()\n",
    "\n",
    "    # initialize frequency dictionaries\n",
    "    # add all the emotion labels as keys\n",
    "    for label in emotion_labels:\n",
    "        total_emotion_freq[label] = dict()\n",
    "        for emotion in emotion_labels:\n",
    "            total_emotion_freq[label][emotion] = 0\n",
    "\n",
    "    # add all the polarity labels as keys\n",
    "    for label in polarity_labels:\n",
    "        total_polarity_freq[label] = dict()\n",
    "        for polarity in polarity_labels:\n",
    "            total_polarity_freq[label][polarity] = 0\n",
    "\n",
    "    return total_emotion_freq, total_polarity_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the frequency dictionaries\n",
    "total_emotion_freq, total_polarity_freq = init_freq_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the emotion and polarity frequencies for each row in the specialized and generalized datasets\n",
    "def calculate_freq(row):\n",
    "    freq = dict()\n",
    "\n",
    "    # if the comment has a polarity with a value greater than 0\n",
    "    # and the reply has a polarity with a value greater than 0\n",
    "    # we will increment this polarity pair count\n",
    "    for comment_label in polarity_labels:\n",
    "        if row[comment_label + '_comment'] > 0:\n",
    "\n",
    "            for reply_label in polarity_labels:\n",
    "                if row[reply_label + '_reply'] > 0:\n",
    "                    total_polarity_freq[comment_label][reply_label] += 1\n",
    "\n",
    "    # we will do a similar operation for the emotions\n",
    "    for comment_label in emotion_labels:\n",
    "        # if the comment has an emotion, we will check emotion of replies\n",
    "        if row[comment_label + '_comment'] > 0:\n",
    "            if comment_label not in freq:\n",
    "                freq[comment_label] = dict()\n",
    "            for reply_label in emotion_labels:\n",
    "                # if the reply has an emotion, we will increment its count\n",
    "                if row[reply_label + '_reply'] > 0:\n",
    "                    if reply_label not in freq[comment_label]:\n",
    "                        freq[comment_label][reply_label] = 0\n",
    "                    freq[comment_label][reply_label] += 1\n",
    "                    total_emotion_freq[comment_label][reply_label] += 1\n",
    "    \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the emotion frequency for generalized dataset\n",
    "g_comment_reply_emotion_freq = g_emotions_df.apply(calculate_freq, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will convert the total emotion and polarity frequencies into dataframes\n",
    "g_polarity_freq_df = pd.DataFrame(total_polarity_freq)\n",
    "g_emotion_freq_df = pd.DataFrame(total_emotion_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_emotion_freq_plot = g_emotion_freq_df.plot(kind='bar', figsize=(12,5))\n",
    "g_emotion_freq_plot.set_xlabel(\"Comment Emotion\")\n",
    "g_emotion_freq_plot.set_ylabel(\"Count\")\n",
    "g_emotion_freq_plot.set_title(\"Generalized Subreddits Comment and Reply Emotion Frequency\")\n",
    "g_emotion_freq_plot.legend(loc='upper right', bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_polarity_freq_plot = g_polarity_freq_df.plot(kind='bar', figsize=(5,5))\n",
    "g_polarity_freq_plot.set_xlabel(\"Comment Polarity\")\n",
    "g_polarity_freq_plot.set_ylabel(\"Count\")\n",
    "g_polarity_freq_plot.set_title(\"Generalized Subreddits Comment and Reply Polarity Frequency\")\n",
    "g_polarity_freq_plot.legend(loc='upper left', bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will conduct the same process for the specialized communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinitialize the frequency dictionaries\n",
    "total_emotion_freq, total_polarity_freq = init_freq_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the emotion frequency for generalized dataset\n",
    "sp_comment_reply_emotion_freq = sp_emotions_df.apply(calculate_freq, axis=1)\n",
    "\n",
    "# convert the total emotion and polarity frequencies into dataframes\n",
    "sp_polarity_freq_df = pd.DataFrame(total_polarity_freq)\n",
    "sp_emotion_freq_df = pd.DataFrame(total_emotion_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_emotion_freq_plot = sp_emotion_freq_df.plot(kind='bar', figsize=(12,5))\n",
    "sp_emotion_freq_plot.set_xlabel(\"Comment Emotion\")\n",
    "sp_emotion_freq_plot.set_ylabel(\"Count\")\n",
    "sp_emotion_freq_plot.set_title(\"Specialized Subreddits Comment and Reply Emotion Frequency\")\n",
    "sp_emotion_freq_plot.legend(loc='upper right', bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_polarity_freq_plot = sp_polarity_freq_df.plot(kind='bar', figsize=(5,5))\n",
    "sp_polarity_freq_plot.set_xlabel(\"Comment Polarity\")\n",
    "sp_polarity_freq_plot.set_ylabel(\"Count\")\n",
    "sp_polarity_freq_plot.set_title(\"Specialized Subreddits Comment and Reply Polarity Frequency\")\n",
    "sp_polarity_freq_plot.legend(loc='upper left', bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. How do the attitudes differ in replies to positively voted comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in positive comments and replies dataset for specialized subreddits\n",
    "pos_piano_df = pd.read_csv('./data/specialized/positive_comments_piano_w_replies.csv')\n",
    "pos_guitars_df = pd.read_csv('./data/specialized/positive_comments_guitars_w_replies.csv')\n",
    "pos_photography_df = pd.read_csv('./data/specialized/positive_comments_photography_w_replies.csv')\n",
    "\n",
    "# combine into one dataframe and drop rows that contain NA values\n",
    "sp_pos_df = pd.concat([pos_piano_df, pos_guitars_df, pos_photography_df])\n",
    "sp_pos_df = sp_pos_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in positive comments and replies dataset for generalized subreddits\n",
    "pos_askReddit_df = pd.read_csv('./data/generalized/positive_comments_AskReddit_w_replies.csv')\n",
    "pos_funny_df = pd.read_csv('./data/generalized/positive_comments_funny_w_replies.csv')\n",
    "pos_todayilearned_df = pd.read_csv('./data/generalized/positive_comments_todayilearned_w_replies.csv')\n",
    "\n",
    "# combine into one dataframe and drop rows that contain NA values\n",
    "g_pos_df = pd.concat([pos_askReddit_df, pos_funny_df, pos_todayilearned_df])\n",
    "g_pos_df = g_pos_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the emotion dataframes for the positive comments and replies for both specialized and generalized datasets\n",
    "g_pos_emotions_df, g_pos_comment_emotions_df, g_pos_reply_emotions_df = get_emotions_df(g_pos_df)\n",
    "sp_pos_emotions_df, sp_pos_comment_emotions_df, sp_pos_reply_emotions_df = get_emotions_df(sp_pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sums of each emotion for the replies in the specialized and generalized datasets\n",
    "sp_pos_reply_emotion_sums = sp_pos_reply_emotions_df.drop(['positive', 'negative'], axis=1).sum().sort_values(ascending=False)\n",
    "g_pos_reply_emotion_sums = g_pos_reply_emotions_df.drop(['positive', 'negative'], axis=1).sum().sort_values(ascending=False)\n",
    "\n",
    "# get the sums of each polarity for the replies in the specialized and generalized datasets\n",
    "sp_pos_reply_polarity = sp_pos_reply_emotions_df[['positive', 'negative']].sum().sort_values(ascending=False)\n",
    "g_pos_reply_polarity = g_pos_reply_emotions_df[['positive', 'negative']].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to keep the colors consistent, we will use the same color map as before\n",
    "sp_pos_emotion_colors = [emotion_color_map[label] for label in sp_pos_reply_emotion_sums.index]\n",
    "g_pos_emotion_colors = [emotion_color_map[label] for label in g_pos_reply_emotion_sums.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pie(sp_pos_reply_emotion_sums.values, labels=sp_pos_reply_emotion_sums.index, autopct='%1.1f%%', colors=sp_pos_emotion_colors)\n",
    "plt.title(\"Specialized Subreddits Reply Emotion Sums\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.pie(sp_pos_reply_polarity.values, labels=sp_pos_reply_polarity.index, autopct='%1.1f%%')\n",
    "plt.title(\"Specialized Subreddits Reply Polarity Sums\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.pie(g_pos_reply_emotion_sums.values, labels=g_pos_reply_emotion_sums.index, autopct='%1.1f%%', colors=g_pos_emotion_colors)\n",
    "plt.title(\"Generalized Subreddits Reply Emotion Sums\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.pie(g_pos_reply_polarity.values, labels=g_pos_reply_polarity.index, autopct='%1.1f%%')\n",
    "plt.title(\"Generalized Subreddits Reply Polarity Sums\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
